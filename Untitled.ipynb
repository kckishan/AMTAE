{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def PairEnum(x,mask=None):\n",
    "    # Enumerate all pairs of feature in x\n",
    "    assert x.ndimension() == 2, 'Input dimension must be 2'\n",
    "    x1 = x.repeat(x.size(0),1)\n",
    "    x2 = x.repeat(1,x.size(0)).view(-1,x.size(1))\n",
    "    if mask is not None:\n",
    "        xmask = mask.view(-1,1).repeat(1,x.size(1))\n",
    "        #dim 0: #sample, dim 1:#feature \n",
    "        x1 = x1[xmask].view(-1,x.size(1))\n",
    "        x2 = x2[xmask].view(-1,x.size(1))\n",
    "    return x1,x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[1, 2], [3, 4], [1,3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Class2Simi(x,mode='cls',mask=None):\n",
    "    # Convert class label to pairwise similarity\n",
    "    n=x.nelement()\n",
    "    assert (n-x.ndimension()+1)==n,'Dimension of Label is not right'\n",
    "    expand1 = x.view(-1,1).expand(n,n)\n",
    "    expand2 = x.view(1,-1).expand(n,n)\n",
    "    out = expand1 - expand2    \n",
    "    out[out!=0] = -1 #dissimilar pair: label=-1\n",
    "    out[out==0] = 1 #Similar pair: label=1\n",
    "    if mode=='cls':\n",
    "        out[out==-1] = 0 #dissimilar pair: label=0\n",
    "    if mode=='hinge':\n",
    "        out = out.float() #hingeloss require float type\n",
    "    if mask is None:\n",
    "        out = out.view(-1)\n",
    "    else:\n",
    "        mask = mask.detach()\n",
    "        out = out[mask]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  torch.Tensor([0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Class2Simi(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "eps = 1e-7  # Avoid calculating log(0). Use the small value of float16. It also works fine using 1e-35 (float32).\n",
    "\n",
    "class KLDiv(nn.Module):\n",
    "    # Calculate KL-Divergence\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        assert predict.ndimension()==2,'Input dimension must be 2'\n",
    "        target = target.detach()\n",
    "\n",
    "        # KL(T||I) = \\sum T(logT-logI)\n",
    "        predict += eps\n",
    "        target += eps\n",
    "        logI = predict.log()\n",
    "        logT = target.log()\n",
    "        TlogTdI = target * (logT - logI)\n",
    "        kld = TlogTdI.sum(1)\n",
    "        return kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KCL(nn.Module):\n",
    "    # KLD-based Clustering Loss (KCL)\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(KCL,self).__init__()\n",
    "        self.kld = KLDiv()\n",
    "        self.hingeloss = nn.HingeEmbeddingLoss(margin)\n",
    "\n",
    "    def forward(self, prob1, prob2, simi):\n",
    "        # simi: 1->similar; -1->dissimilar; 0->unknown(ignore)\n",
    "        assert len(prob1)==len(prob2)==len(simi), 'Wrong input size:{0},{1},{2}'.format(str(len(prob1)),str(len(prob2)),str(len(simi)))\n",
    "\n",
    "        kld = self.kld(prob1,prob2)\n",
    "        output = self.hingeloss(kld,simi)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = PairEnum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCL(nn.Module):\n",
    "    # Meta Classification Likelihood (MCL)\n",
    "\n",
    "    eps = 1e-7 # Avoid calculating log(0). Use the small value of float16.\n",
    "        \n",
    "    def forward(self, prob1, prob2, simi):\n",
    "        # simi: 1->similar; -1->dissimilar; 0->unknown(ignore)\n",
    "        assert len(prob1)==len(prob2)==len(simi), 'Wrong input size:{0},{1},{2}'.format(str(len(prob1)),str(len(prob2)),str(len(simi)))\n",
    "\n",
    "        P = prob1.mul_(prob2)\n",
    "        P = P.sum(1)\n",
    "        P.mul_(simi).add_(simi.eq(-1).type_as(P))\n",
    "        neglogP = -P.add_(MCL.eps).log_()\n",
    "        return neglogP.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = MCL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.4359)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(x1, x2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
